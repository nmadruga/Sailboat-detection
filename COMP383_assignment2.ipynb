{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmadruga/Sailboat-detection/blob/main/COMP383_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioai2s9SSanq",
        "outputId": "658b8aee-6c79-467a-b042-66b9bbde3fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: ROBOFLOW_KEY_SAILBOATS=xxx\n",
            "env: ROBOFLOW_KEY_LARGE_DATASET=yyy\n"
          ]
        }
      ],
      "source": [
        "%env ROBOFLOW_KEY_SAILBOATS=xxx\n",
        "%env ROBOFLOW_KEY_LARGE_DATASET=yyy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDnkazLjo7ms",
        "outputId": "88460060-04e5-46f8-c784-1d588836502d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import os, io\n",
        "import torch\n",
        "import torchvision\n",
        "import glob as glob\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import requests\n",
        "import random\n",
        "import numpy as np\n",
        "import zipfile\n",
        "\n",
        "!pip install torch torchvision\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "TRAIN = True\n",
        "EPOCHS = 15 # Number of epochs to train for.\n",
        "\n",
        "def download_file(url, save_name):\n",
        "    if save_name == './' or not os.path.exists(save_name):\n",
        "        r = requests.get(url)\n",
        "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "        z.extractall(save_name)\n",
        "        print(f'Finished extractin zip file: {z}')\n",
        "    else:\n",
        "        print('Folder already present, skipping download...')\n",
        "\n",
        "if not os.path.exists('train'):\n",
        "  url = 'https://app.roboflow.com/ds/wiOoYE9Lxh?key='+os.environ['ROBOFLOW_KEY_LARGE_DATASET']\n",
        "  download_file(url, './')\n",
        "else: \n",
        "  print('Dataset already present, skipping download...')\n",
        "\n",
        "  # dirs = ['train', 'valid', 'test']\n",
        "\n",
        "  # for i, dir_name in enumerate(dirs):\n",
        "  #     all_image_names = sorted(os.listdir(f\"dataset/{dir_name}/images/\"))\n",
        "  #     for j, image_name in enumerate(all_image_names):\n",
        "  #         if (j % 2) == 0:\n",
        "  #             file_name = image_name.split('.jpg')[0]\n",
        "  #             os.remove(f\"dataset/{dir_name}/images/{image_name}\")\n",
        "  #             os.remove(f\"dataset/{dir_name}/labels/{file_name}.txt\")\n",
        "\n",
        "def download_file(url, save_name):\n",
        "  url = url\n",
        "  if not os.path.exists(save_name):\n",
        "      file = requests.get(url)\n",
        "      open(save_name, 'wb').write(file.content)\n",
        "  else: \n",
        "      print('File already present, skipping download...')\n",
        "\n",
        "class_names = ['Boat','kayak','motorboat','sailboat']\n",
        "colors = np.random.uniform(0, 255, size=(len(class_names), 3))\n",
        "\n",
        "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
        "def yolo2bbox(bboxes):\n",
        "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
        "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
        "    return xmin, ymin, xmax, ymax\n",
        "\n",
        "def plot_box(image, bboxes, labels):\n",
        "    # Need the image height and width to denormalize\n",
        "    # the bounding box coordinates\n",
        "    h, w, _ = image.shape\n",
        "    for box_num, box in enumerate(bboxes):\n",
        "        x1, y1, x2, y2 = yolo2bbox(box)\n",
        "        # denormalize the coordinates\n",
        "        xmin = int(x1*w)\n",
        "        ymin = int(y1*h)\n",
        "        xmax = int(x2*w)\n",
        "        ymax = int(y2*h)\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "        \n",
        "        class_name = class_names[int(labels[box_num])]\n",
        "        \n",
        "        cv2.rectangle(\n",
        "            image, \n",
        "            (xmin, ymin), (xmax, ymax),\n",
        "            color=colors[class_names.index(class_name)],\n",
        "            thickness=2\n",
        "        ) \n",
        "\n",
        "        font_scale = min(1,max(3,int(w/500)))\n",
        "        font_thickness = min(2, max(10,int(w/50)))\n",
        "        \n",
        "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
        "        # Text width and height\n",
        "        tw, th = cv2.getTextSize(\n",
        "            class_name, \n",
        "            0, fontScale=font_scale, thickness=font_thickness\n",
        "        )[0]\n",
        "        p2 = p1[0] + tw, p1[1] + -th - 10\n",
        "        cv2.rectangle(\n",
        "            image, \n",
        "            p1, p2,\n",
        "            color=colors[class_names.index(class_name)],\n",
        "            thickness=-1,\n",
        "        )\n",
        "        cv2.putText(\n",
        "            image, \n",
        "            class_name,\n",
        "            (xmin+1, ymin-10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            font_scale,\n",
        "            (255, 255, 255),\n",
        "            font_thickness\n",
        "        )\n",
        "    return image\n",
        "\n",
        "# Function to plot images with the bounding boxes.\n",
        "def plot(image_paths, label_paths, num_samples):\n",
        "  all_training_images = glob.glob(image_paths)\n",
        "  all_training_labels = glob.glob(label_paths)\n",
        "  all_training_images.sort()\n",
        "  all_training_labels.sort()\n",
        "  \n",
        "  num_images = len(all_training_images)\n",
        "  \n",
        "  plt.figure(figsize=(15, 12))\n",
        "  for i in range(num_samples):\n",
        "      j = random.randint(0,num_images-1)\n",
        "      image = cv2.imread(all_training_images[j])\n",
        "      with open(all_training_labels[j], 'r') as f:\n",
        "        print(f'{j} labels:', all_training_labels[j])\n",
        "        bboxes = []\n",
        "        labels = []\n",
        "        label_lines = f.readlines()\n",
        "        for label_line in label_lines:\n",
        "            label = label_line[0]\n",
        "            bbox_string = label_line[2:]\n",
        "            x_c, y_c, w, h = bbox_string.split(' ')\n",
        "            x_c = float(x_c)\n",
        "            y_c = float(y_c)\n",
        "            w = float(w)\n",
        "            h = float(h)\n",
        "            bboxes.append([x_c, y_c, w, h])\n",
        "            labels.append(label)\n",
        "        result_image = plot_box(image, bboxes, labels)\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.imshow(result_image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "  plt.subplots_adjust(wspace=0)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# ## Run different models and check accuracy of detection in num_samples\n",
        "# def check_models(model_paths, num_samples):\n",
        "#  all_testing_images = glob.glob('test/images/*')\n",
        "\n",
        "#  # Select a sample set to test detect images\n",
        "#  sample_images = random.choices(all_testing_images, k=num_samples)\n",
        "\n",
        "#  images = []\n",
        "#  for image_path in sample_images:\n",
        "#     image = torchvision.io.read_image(image_path).float() / 255.0\n",
        "#     images.append(image.unsqueeze(0))\n",
        "\n",
        "#  # Compare the models\n",
        "#  for model_name, model_path in model_paths.items():\n",
        "#     # Load the model\n",
        "#     model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
        "#     model.eval()\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(image)\n",
        "\n",
        "#     # Print the results\n",
        "#     print(f'Model: {model_name} - Image: {image}')\n",
        "#     results = outputs.pandas().xyxy[0]\n",
        "#     print(results)\n",
        "#     print()\n",
        "\n",
        "def set_res_dir():\n",
        "    # Directory to store results\n",
        "    res_dir_count = len(glob.glob('runs/train/*'))\n",
        "    print(f\"Current number of result directories: {res_dir_count}\")\n",
        "    if TRAIN:\n",
        "        RES_DIR = f\"results_{res_dir_count+1}\"\n",
        "        print(RES_DIR)\n",
        "    else:\n",
        "        RES_DIR = f\"results_{res_dir_count}\"\n",
        "    return RES_DIR\n",
        "\n",
        "def monitor_tensorboard():\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir runs/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr5Otqc06cWK"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('yolov5'):\n",
        "    !git clone https://github.com/ultralytics/yolov5.git\n",
        "\n",
        "%cd yolov5/\n",
        "!pwd\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDbkTza5yJ8K"
      },
      "outputs": [],
      "source": [
        "# Visualize a few training images.\n",
        "plot(\n",
        "    image_paths='train/images/*', \n",
        "    label_paths='train/labels/*',\n",
        "    num_samples=4,\n",
        ")\n",
        "\n",
        "# # Define the YOLOv5 models to compare\n",
        "# check_models(\n",
        "#     model_paths={\n",
        "#     'yolov5s': 'yolov5s.pt',\n",
        "#     'yolov5m': 'yolov5m.pt',\n",
        "#     'yolov5l': 'yolov5l.pt',\n",
        "#     'yolov5x': 'yolov5x.pt'\n",
        "#     },\n",
        "#     num_samples=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcZfSRQtqEXz"
      },
      "outputs": [],
      "source": [
        "monitor_tensorboard()\n",
        "\n",
        "RES_DIR = set_res_dir()\n",
        "if TRAIN:\n",
        "  %cd yolov5\n",
        "\n",
        "  # !python train.py --data ../data.yaml --weights yolov5s.pt \\\n",
        "  # --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR} --single-cls\n",
        "\n",
        "  # !python train.py --data ../data.yaml --weights yolov5m.pt \\\n",
        "  # --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR} --single-cls\n",
        "\n",
        "  !python train.py --data ../data.yaml --weights yolov5l.pt \\\n",
        "  --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR} --single-cls\n",
        "\n",
        "  # !python train.py --data ../data.yaml --weights yolov5x.pt \\\n",
        "  # --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR} --single-cls\n",
        "\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFXiu2bFUaWT"
      },
      "outputs": [],
      "source": [
        "# Function to show validation predictions saved during training.\n",
        "def show_valid_results(RES_DIR):\n",
        "    !ls runs/train/{RES_DIR}\n",
        "    EXP_PATH = f\"runs/train/{RES_DIR}\"\n",
        "    validation_pred_images = glob.glob(f\"{EXP_PATH}/*_pred.jpg\")\n",
        "    print(validation_pred_images)\n",
        "    for pred_image in validation_pred_images:\n",
        "        image = cv2.imread(pred_image)\n",
        "        plt.figure(figsize=(19, 16))\n",
        "        plt.imshow(image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Helper function for inference on images.\n",
        "def inference(RES_DIR, data_path):\n",
        "    # Directory to store inference results.\n",
        "    infer_dir_count = len(glob.glob('runs/detect/*'))\n",
        "    print(f\"Current number of inference detection directories: {infer_dir_count}\")\n",
        "    INFER_DIR = f\"inference_{infer_dir_count+1}\"\n",
        "    print(INFER_DIR)\n",
        "    # Inference on images.\n",
        "    !python detect.py --weights runs/train/{RES_DIR}/weights/best.pt \\\n",
        "    --source {data_path} --name {INFER_DIR}\n",
        "    return INFER_DIR\n",
        "\n",
        "def visualize(INFER_DIR):\n",
        "# Visualize inference images.\n",
        "    INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n",
        "    infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n",
        "    print(infer_images)\n",
        "    for pred_image in infer_images:\n",
        "        image = cv2.imread(pred_image)\n",
        "        plt.figure(figsize=(19, 16))\n",
        "        plt.imshow(image[:, :, ::-1])\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSwyBGf1UeTW"
      },
      "outputs": [],
      "source": [
        "%cd yolov5\n",
        "\n",
        "show_valid_results(RES_DIR)\n",
        "\n",
        "if not os.path.exists('inference_images'):\n",
        "  url = 'https://app.roboflow.com/ds/1fBU7vhVon?key'+os.environ['ROBOFLOW_KEY_SAILBOATS']\n",
        "  download_file(url, \"inference_images\")\n",
        "else:\n",
        "  print('Dataset already present')\n",
        "\n",
        "# Inference on images.\n",
        "IMAGE_INFER_DIR = inference(RES_DIR, 'inference_images/test')\n",
        "\n",
        "visualize(IMAGE_INFER_DIR)\n",
        "\n",
        "monitor_tensorboard()\n",
        "\n",
        "RES_DIR = set_res_dir()\n",
        "if TRAIN:\n",
        "    !python train.py --data {IMAGE_INFER_DIR}/data.yaml --weights yolov5l.pt \\\n",
        "    --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}\n",
        "\n",
        "%cd .."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb6+3z9KUqlbnCE+UYvgjX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}